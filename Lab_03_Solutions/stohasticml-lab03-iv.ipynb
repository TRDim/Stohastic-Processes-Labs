{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1><b>Άσκηση 4</b></h1>\n<p align=\"justify\">Η μέθοδος Monte Carlo είναι μια υπολογιστική μέθοδος, που βασίζεται στο νόμο των μεγάλων αριθμών. Αν {Χ<sub>n</sub>}<sub>n∈N</sub> είναι μια ακολουθία από ανεξάρτητες, ισόνομες τυχαίες μεταβλητές, με πεπερασμένη μέση τιμή Ε[Χ], τότε:</p>\n\n$$\nP\\left[\n\\frac{1}{n}\\sum_{k=1}^{n}X_k \\rightarrow E[X]\n\\right] = 1\n$$\n\n<p align=\"justify\">Προκειμένου να υπολογίσουμε τη μέση τιμή Ε[Χ]  μιας τυχαίας μεταβλητής Χ, μπορούμε λοιπόν να πάρουμε το μέσο όρο ενός μεγάλου αριθμού ανεξάρτητων δειγμάτων αυτής της μεταβλητής. Με παρόμοιο τρόπο, μπορούμε να προσεγγίσουμε υπολογιστικά την πιθανότητα ενός ενδεχομένου από το κλάσμα των πραγματοποιήσεών του σε μια σειρά από <b>m</b> ανεξάρτητες προσομοιώσεις μέχρι το βήμα <b>n</b>, δηλαδή:</p>\n\n$$\nP\\left[\n\\frac{1}{m} \\sum_{k=1}^{m}H_k \\rightarrow P[X_n | X_0]\n\\right] = 1\n$$\n\n<p align=\"justify\">όπου η τυχαία μεταβλητή Η_k παίρνει την τιμή 1 εάν το ενδεχόμενο πραγματοποιείται στο τέλος του εκάστοτε πειράματος και 0 στην αντίθετη περίπτωση. Σ’ αυτήν την ιδέα θα βασιστεί η άσκηση αυτή. Σας δίνεται η μαρκοβιανή αλυσίδα στο χώρο καταστάσεων <b>Χ</b>={1,2,3} με πίνακα πιθανοτήτων μετάβασης:</p>\n\n$$\nP = \\begin{pmatrix}\n0 & 1 & 0\\\\\n0 & 2/3 & 1/3\\\\\n1/6 & 5/6 & 0\n\\end{pmatrix}\n$$\n\n<p align=\"justify\">Χρησιμοποιώντας το πρόγραμμα που δίνεται παρακάτω, θα πραγματοποιήσετε <b>m</b> ανεξάρτητα πειράματα για να εκτιμήσετε την πιθανότητα <b>Για να τρέξετε το πρόγραμμα θα πρέπει να έχετε φορτώσει το αρχείο <i><a href=\"https://github.com/nkostopoulos/StochasticsLabPublic/blob/master/lab3/simple_markov_chain_lib.py\">simple_markov_chain_lib.py</a></i></b>.</p>\n\n$$\nP\\left[\nX_{40} = 1 | X_0 = 1\n\\right]\n$$\n\n<p align=\"justify\">δηλαδή την πιθανότητα να βρίσκεται η αλυσίδα στην κατάσταση 1 στο 40ό βήμα της δεδομένου ότι ξεκίνησε από την κατάσταση 1. Για να ελέγξετε την ορθότητα της μεθόδου, το πρόγραμμα περιλαμβάνει και τον ακριβή υπολογισμό της παραπάνω πιθανότητας.</p> \n<ul>\n<li>Να μελετήσετε το πρόγραμμα και να περιγράψετε σύντομα τη μέθοδο που ακολουθείται.</li>\n<li>Να επαναλάβετε τη διαδικασία για τιμές της παραμέτρου m: (α) 1,000, (β) 10,000, (γ) 50,000, (δ) 100,000, (ε) 500,000. Να καταγράψετε και να σχολιάσετε την τιμή της παραπάνω πιθανότητας όπως υπολογίζεται από την προσομοίωση σε σχέση με την ακριβή τιμή της.</li>\n</ul>\n","metadata":{"id":"0LsZdK1LTB1T"}},{"cell_type":"code","source":"from __future__ import division\nimport os \nos.chdir('/kaggle/input/simple-markov-chain')\nfrom simple_markov_chain_lib import markov_chain\nimport statistics as stat\nfrom numpy import matmul\nimport numpy as np\n\ndef defineMarkovTable(): \n\tp = 1/6\n\tmarkov_table = {\n\t\t1: {2: 1.},\n\t\t2: {2: 2/3, 3: 1/3},\n\t\t3: {1: p, 2: 1-p}\n\t}\n\n\treturn markov_table\n\ndef defineNumpyTable():\n\tPn = np.array([[0,1,0],\n\t\t       [0,2/3,1/3],\n\t\t       [1/6, 5/6, 0]])\n\tP0 = np.array([[1,0,0]])\n\t\n\treturn Pn,P0\n\ndef multiplyNumpyTables(Pn,P0):\n\tfor index in range(40):\n\t\tPn = np.matmul(Pn,Pn)\n\tPn = np.matmul(P0,Pn)\n\treturn Pn\n\ndef defineInitDistribution():\n\tinit_dist = {1: 1.}\n\t\n\treturn init_dist\n\ndef calculateProbabilities(markov_table, init_dist, experiments):\n\tmc = markov_chain(markov_table, init_dist)\n\t#experiments = 500000\n\tsteps = 40\n\tvisits = 0\n\n\tfor index in range(experiments):\n\t\tmc.start()\n\t\tfor j in range(steps):\n\t\t\tmc.move()\n\t\tif mc.running_state == 1: visits += 1\n\n\tprobability = visits / experiments\n\treturn probability\n\nif __name__ == \"__main__\":\n    markov_table = defineMarkovTable()\n    init_dist = defineInitDistribution()\n    exp = [int(1e3),int(1e4),int(5e4),int(1e5),int(5e5)]\n    \n    for i in exp:\n        probability = calculateProbabilities(markov_table, init_dist,i)\n        print('Number of Exp:',i, 'Probability:',probability)\n\n        Pn,P0 = defineNumpyTable()\n        realProbability = multiplyNumpyTables(Pn,P0)\n        print(realProbability)","metadata":{"id":"gkMG5r8WX1np","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Για τον υπολογισμό της πιθανότητας: \n\n$ P = [ X_{40}=1 | X_0 = 1]$\n(Ξεκινώντας από την θέση **1** μετλα απο **40** επαναλήψεις να βρίσκεται και πάλι στην θέση **1**),\n\nτο πρόγραμμα ακολουθεί 2 διαφορετικούς τρόπους για τον υπολογισμό της. \n\n> 1. Αναλυτικός τρόπος υπολογισμού:\n\n$π_0 = [1\\quad 0\\quad 0]\\quad  και\\quad \n P = \\begin{bmatrix}\n     0 & 1 & 0 \\\\\n     0 & \\frac{2}{3} & 0\\\\ \n     \\frac{1}{6}& \\frac{5}{6} & 0\\\\ \n     \\end{bmatrix}$\n     \nΧρησιμοποιούμε την σχέση: \n$ π_{40} = π_0 P^{40}$\n\nΥπολογίζεται χρησιμοποιώντας την συνάρτηση np.matmul της numpy ως εξής:    \n   \n   **array([[0.04, 0.72, 0.24]])**","metadata":{}},{"cell_type":"code","source":"P = np.array([[0,1,0],[0,2/3,1/3],[1/6,5/6,0]])\nPo= np.array([[1,0,0]])\nnp.matmul(Po,np.linalg.matrix_power(P,40))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> 2. Χρησιμοποιώντας την μέθοδο Monte Carlo:\nΌπως το πραγματοποιήσαμε παραπάνω με βάση το αρχείο simple_markov_chan_lib.py. ","metadata":{}},{"cell_type":"markdown","source":"> Παρατηρήσεις για διαφορετικό αριθμό πειραμάτων:\nΠαρατηρούμε ότι ανάλογα με τον αριθμό των προσομοιώσεων έχουμε διαφορετική πιθανότητα. Μιας και ο αλγόριθμος Monte Carlo βασίζεται στο νόμο των μεγάλων αριθμών, όσο μεγαλύτερος ο αριθμός των επαναλήψεων τόσο πιο σίγουροι είμαστε ότι ο αλγόριθμος θα συγκλινει στην πραγματική τιμή. ","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}